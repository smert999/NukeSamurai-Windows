# üöÄ SAM 3: –†–µ–≤–æ–ª—é—Ü–∏—è –≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ - –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑

> **Meta AI –ø—Ä–µ–¥—Å—Ç–∞–≤–∏–ª–∞ SAM 3 - —Å–ª–µ–¥—É—é—â–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ Segment Anything Model**  
> –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–ª–∏–∑: –ù–æ—è–±—Ä—å 2025  
> –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: https://github.com/facebookresearch/sam3  
> –°–∞–π—Ç: https://ai.meta.com/sam3/

---

## üìñ –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–ß—Ç–æ —Ç–∞–∫–æ–µ SAM 3?](#—á—Ç–æ-—Ç–∞–∫–æ–µ-sam-3)
2. [–ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è](#–∫–ª—é—á–µ–≤—ã–µ-—É–ª—É—á—à–µ–Ω–∏—è)
3. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
4. [–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏](#–Ω–æ–≤—ã–µ-–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)
5. [–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å SAM 2.1](#—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ-—Å-sam-21)
6. [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö](#—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã-–Ω–∞-–±–µ–Ω—á–º–∞—Ä–∫–∞—Ö)
7. [–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ VFX](#–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ-–≤-vfx)
8. [–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ NukeSamurai](#–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è-–≤-nukesamurai)
9. [–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è](#—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
10. [–ó–∞–∫–ª—é—á–µ–Ω–∏–µ](#–∑–∞–∫–ª—é—á–µ–Ω–∏–µ)

---

## üéØ –ß—Ç–æ —Ç–∞–∫–æ–µ SAM 3?

**SAM 3 (Segment Anything Model 3)** - —ç—Ç–æ —Ç—Ä–µ—Ç—å–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –æ—Ç Meta AI. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–µ—Ä—Å–∏–π, SAM 3 –≤–≤–æ–¥–∏—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏—é **"Segment Anything with Concepts"** - —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é —á–µ—Ä–µ–∑ –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ.

### –û—Å–Ω–æ–≤–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:

- **848M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** (–Ω–∞ 26% –±–æ–ª—å—à–µ, —á–µ–º SAM 2.1)
- **Text-based prompting** –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
- **Visual exemplar prompts** - —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –ø—Ä–∏–º–µ—Ä—É –æ–±—ä–µ–∫—Ç–∞
- **Unified architecture** –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ
- **–û—Ç–∫—Ä—ã—Ç—ã–π –∫–æ–¥** –ø–æ–¥ Apache 2.0 License

---

## üî• –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### 1. **Text Prompts - –†–µ–≤–æ–ª—é—Ü–∏—è –≤ workflow** üéØ

–≠—Ç–æ –≥–ª–∞–≤–Ω–æ–µ –Ω–æ–≤–æ–≤–≤–µ–¥–µ–Ω–∏–µ SAM 3. –¢–µ–ø–µ—Ä—å –≤–º–µ—Å—Ç–æ —Ä–∏—Å–æ–≤–∞–Ω–∏—è bounding box –∏–ª–∏ —Ç–æ—á–µ–∫, –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ **–Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º** —á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏.

#### –ü—Ä–∏–º–µ—Ä—ã:

**–ü—Ä–æ—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã:**
```python
"car"           # –í—Å–µ –º–∞—à–∏–Ω—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
"person"        # –í—Å–µ –ª—é–¥–∏
"tree"          # –í—Å–µ –¥–µ—Ä–µ–≤—å—è
"building"      # –í—Å–µ –∑–¥–∞–Ω–∏—è
```

**–ó–∞–ø—Ä–æ—Å—ã —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏:**
```python
"red car"              # –¢–æ–ª—å–∫–æ –∫—Ä–∞—Å–Ω—ã–µ –º–∞—à–∏–Ω—ã
"person in blue shirt" # –ß–µ–ª–æ–≤–µ–∫ –≤ —Å–∏–Ω–µ–π —Ä—É–±–∞—à–∫–µ
"large tree"           # –ë–æ–ª—å—à–∏–µ –¥–µ—Ä–µ–≤—å—è
"tall building"        # –í—ã—Å–æ–∫–∏–µ –∑–¥–∞–Ω–∏—è
```

**–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã:**
```python
"car on the road"      # –ú–∞—à–∏–Ω–∞ –∏–º–µ–Ω–Ω–æ –Ω–∞ –¥–æ—Ä–æ–≥–µ
"person walking"       # –ò–¥—É—â–∏–π —á–µ–ª–æ–≤–µ–∫ (–Ω–µ —Å—Ç–æ—è—â–∏–π)
"bird in the sky"      # –ü—Ç–∏—Ü–∞ –≤ –Ω–µ–±–µ
"dog near the house"   # –°–æ–±–∞–∫–∞ –≤–æ–∑–ª–µ –¥–æ–º–∞
```

**–†–µ–ª—è—Ç–∏–≤–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã:**
```python
"car in front of the building"  # –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è
"person behind the tree"        # –ü–æ–∑–∏—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥—Ä—É–≥–∏—Ö
"cup on the table"              # –û–±—ä–µ–∫—Ç –Ω–∞ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏
```

### 2. **Visual Exemplar Prompts** üñºÔ∏è

–ù–æ–≤–∞—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è: –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç–µ –º–æ–¥–µ–ª–∏ **–ø—Ä–∏–º–µ—Ä –æ–±—ä–µ–∫—Ç–∞**, –∏ –æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ø–æ—Ö–æ–∂–∏–µ.

**Use cases:**
- **–û–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã:** –í—ã–¥–µ–ª–∏–ª–∏ –æ–¥–∏–Ω —Å—Ç—É–ª ‚Üí –º–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ 100 —Å—Ç—É–ª—å–µ–≤
- **–ü–∞—Ç—Ç–µ—Ä–Ω—ã:** –ü–æ–∫–∞–∑–∞–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —É–∑–æ—Ä–∞ ‚Üí –º–æ–¥–µ–ª—å —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–∞—Ç—Ç–µ—Ä–Ω
- **–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã:** –ü–æ–∫–∞–∑–∞–ª–∏ —á–∞—Å—Ç—å –æ–±—ä–µ–∫—Ç–∞ ‚Üí –º–æ–¥–µ–ª—å –Ω–∞—Ö–æ–¥–∏—Ç –≤–µ—Å—å –æ–±—ä–µ–∫—Ç

### 3. **Improved Video Tracking** üé¨

SAM 3 –Ω–∞—Å–ª–µ–¥—É–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Ç—Ä–µ–∫–µ—Ä–∞ SAM 2, –Ω–æ —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏:

- **–ü—Ä–æ–º–ø—Ç—ã –Ω–∞ –ª—é–±–æ–º –∫–∞–¥—Ä–µ** (–Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞ –ø–µ—Ä–≤–æ–º)
- **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã** –≤ –æ–¥–Ω–æ–π —Å–µ—Å—Å–∏–∏
- **–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ** –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **Session management** –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

### 4. **SAM 3 Agent** ü§ñ

–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ **—Å–ª–æ–∂–Ω—ã—Ö –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤**:

```python
"all people wearing red shirts and standing near the car"
```

–ú–æ–¥–µ–ª—å —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ:
1. –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ—Ö –ª—é–¥–µ–π
2. –§–∏–ª—å—Ç—Ä—É–µ—Ç —Ç–µ—Ö, –∫—Ç–æ –≤ –∫—Ä–∞—Å–Ω–æ–π –æ–¥–µ–∂–¥–µ
3. –§–∏–ª—å—Ç—Ä—É–µ—Ç —Ç–µ—Ö, –∫—Ç–æ —Ä—è–¥–æ–º —Å –º–∞—à–∏–Ω–æ–π

### 5. **Negative Prompts** ‚ùå

–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —É–∫–∞–∑—ã–≤–∞—Ç—å —á—Ç–æ **–ù–ï** –Ω—É–∂–Ω–æ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å:

```python
"not person in red"     # –í—Å—ë –∫—Ä–æ–º–µ —á–µ–ª–æ–≤–µ–∫–∞ –≤ –∫—Ä–∞—Å–Ω–æ–º
"not background"        # –í—Å—ë –∫—Ä–æ–º–µ —Ñ–æ–Ω–∞
"all cars except red"   # –í—Å–µ –º–∞—à–∏–Ω—ã –∫—Ä–æ–º–µ –∫—Ä–∞—Å–Ω—ã—Ö
```

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã SAM 3:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SAM 3 Model                        ‚îÇ
‚îÇ                      (848M params)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Vision Encoder  ‚îÇ (shared)‚îÇ  Vision Encoder  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (Hiera-L)      ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ   (Hiera-L)      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ          ‚îÇ                             ‚îÇ               ‚îÇ
‚îÇ          v                             v               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  DETR Detector   ‚îÇ         ‚îÇ  SAM 2 Tracker   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Text cond.    ‚îÇ         ‚îÇ  - Memory attn.  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Geometry      ‚îÇ         ‚îÇ  - Temporal      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Exemplars     ‚îÇ         ‚îÇ  - Interactive   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ          ‚îÇ                             ‚îÇ               ‚îÇ
‚îÇ          v                             v               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Image Results   ‚îÇ         ‚îÇ  Video Results   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Masks         ‚îÇ         ‚îÇ  - Tracked masks ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Boxes         ‚îÇ         ‚îÇ  - Consistency   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Scores        ‚îÇ         ‚îÇ  - Refinement    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:

1. **Shared Vision Encoder (Hiera-L)**
   - –ï–¥–∏–Ω—ã–π —ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ
   - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Hierarchical Vision Transformer

2. **DETR-based Detector**
   - Conditioning –Ω–∞ —Ç—Ä–∏ —Ç–∏–ø–∞ –ø—Ä–æ–º–ø—Ç–æ–≤:
     - Text (–Ω–æ–≤–æ–µ!)
     - Geometry (bbox, points)
     - Visual exemplars (–Ω–æ–≤–æ–µ!)
   - End-to-end –æ–±—É—á–µ–Ω–∏–µ

3. **SAM 2 Tracker (–Ω–∞—Å–ª–µ–¥—É–µ—Ç—Å—è)**
   - Memory attention mechanism
   - Cross-frame consistency
   - Interactive refinement

---

## üé® –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

### 1. Text-based Image Segmentation

```python
from sam3.model_builder import build_sam3_image_model
from sam3.model.sam3_image_processor import Sam3Processor
from PIL import Image

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = build_sam3_image_model()
processor = Sam3Processor(model)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
image = Image.open("scene.jpg")
inference_state = processor.set_image(image)

# TEXT PROMPT!
output = processor.set_text_prompt(
    state=inference_state,
    prompt="red car"
)

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
masks = output["masks"]      # –ú–∞—Å–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
boxes = output["boxes"]      # Bounding boxes
scores = output["scores"]    # Confidence scores
```

### 2. Text-based Video Segmentation

```python
from sam3.model_builder import build_sam3_video_predictor

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
video_predictor = build_sam3_video_predictor()

# –°—Ç–∞—Ä—Ç —Å–µ—Å—Å–∏–∏
response = video_predictor.handle_request(
    request=dict(
        type="start_session",
        resource_path="video.mp4"
    )
)
session_id = response["session_id"]

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ text prompt
response = video_predictor.handle_request(
    request=dict(
        type="add_prompt",
        session_id=session_id,
        frame_index=0,  # –ú–æ–∂–Ω–æ –Ω–∞ –ª—é–±–æ–º –∫–∞–¥—Ä–µ!
        text="person walking"
    )
)

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤
outputs = response["outputs"]
```

### 3. Visual Exemplar Prompting

```python
# –í—ã—Ä–µ–∑–∞–µ–º –ø—Ä–∏–º–µ—Ä –æ–±—ä–µ–∫—Ç–∞
exemplar_crop = image[y:y+h, x:x+w]

# SAM 3 –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ø–æ—Ö–æ–∂–∏–µ
output = processor.set_exemplar_prompt(
    state=inference_state,
    exemplar=exemplar_crop
)
```

### 4. Multi-object Session

```python
# –û–¥–Ω–∞ —Å–µ—Å—Å–∏—è - –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤
session = video_predictor.start_session("video.mp4")

# –û–±—ä–µ–∫—Ç 1
video_predictor.add_prompt(session, frame=0, text="person in blue")

# –û–±—ä–µ–∫—Ç 2
video_predictor.add_prompt(session, frame=0, text="red car")

# –û–±—ä–µ–∫—Ç 3
video_predictor.add_prompt(session, frame=50, text="dog")

# –í—Å–µ –º–∞—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ!
```

### 5. Batched Inference

```python
# –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
images = [img1, img2, img3, ..., imgN]
prompts = ["car", "person", "tree", ...]

outputs = processor.batch_inference(
    images=images,
    prompts=prompts,
    batch_size=8  # GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
)
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å SAM 2.1

| –ü–∞—Ä–∞–º–µ—Ç—Ä | SAM 2.1 | SAM 3 | –£–ª—É—á—à–µ–Ω–∏–µ |
|----------|---------|-------|-----------|
| **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏** | ~670M | 848M | +26% |
| **Text prompts** | ‚ùå | ‚úÖ | –ù–æ–≤–æ–µ! |
| **Bbox/Point prompts** | ‚úÖ | ‚úÖ | –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ |
| **Visual exemplars** | ‚ùå | ‚úÖ | –ù–æ–≤–æ–µ! |
| **Negative prompts** | ‚ùå | ‚úÖ | –ù–æ–≤–æ–µ! |
| **Multi-object tracking** | –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ | ‚úÖ | –£–ª—É—á—à–µ–Ω–æ |
| **Session management** | ‚ùå | ‚úÖ | –ù–æ–≤–æ–µ! |
| **Agent mode** | ‚ùå | ‚úÖ | –ù–æ–≤–æ–µ! |
| **Batched inference** | ‚ùå | ‚úÖ | –ù–æ–≤–æ–µ! |
| **LVIS cgF1** | - | 37.2 | Benchmark |
| **SA-Co/Gold cgF1** | - | 54.1 | Benchmark |
| **COCO AP** | - | 53.6 | Benchmark |

---

## üèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö

### –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (Instance Segmentation)

| Model | LVIS cgF1 | SA-Co/Gold cgF1 | COCO AP |
|-------|-----------|-----------------|---------|
| **Human** | - | **72.8** | - |
| OWLv2 | 29.3 | 24.6 | 45.5 |
| DINO-X | - | 21.3 | 52.4 |
| Gemini 2.5 | 13.4 | 13.0 | - |
| **SAM 3** | **37.2** | **54.1** | **53.6** |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ SAM 3 –ª—É—á—à–µ –≤—Å–µ—Ö —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π
- ‚úÖ –ù–∞ 74% –ø—É—Ç–∏ –∫ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–º—É —É—Ä–æ–≤–Ω—é (SA-Co)
- ‚úÖ –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç DINO-X –∏ Gemini 2.5

### –í–∏–¥–µ–æ (Video Object Segmentation)

| Model | SA-V test | YT-Temporal-1B | SmartGlasses | BURST HOTA |
|-------|-----------|----------------|--------------|------------|
| **Human** | 53.1 | 71.2 | 58.5 | - |
| **SAM 3** | 30.3 | 50.8 | 36.4 | 44.5 |

**–í—ã–≤–æ–¥—ã:**
- ‚úÖ –•–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ö
- ‚úÖ ~71% –æ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è (YT-Temporal)
- ‚ö†Ô∏è –ï—Å—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π

### Box Detection

| Model | COCO AP | LVIS AP | APo (COCO-O) |
|-------|---------|---------|--------------|
| OWLv2 | 46.1 | 43.4 | 23.9 |
| DINO-X | 56.0 | 38.5 | - |
| **SAM 3** | **56.4** | **48.5** | **55.7** |

---

## üé¨ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ VFX

### –°—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

#### 1. **Rotoscoping / Mask Generation** üé≠

**–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π workflow (SAM 2):**
```
1. –ù–∞–π—Ç–∏ –æ–±—ä–µ–∫—Ç –≤ –∫–∞–¥—Ä–µ
2. –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å bbox
3. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥
4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
5. –ò—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ –≤—Ä—É—á–Ω—É—é
```

**–ù–æ–≤—ã–π workflow (SAM 3):**
```
1. –ù–∞–ø–∏—Å–∞—Ç—å: "person in blue jacket"
2. –ó–∞–ø—É—Å—Ç–∏—Ç—å
3. –ì–æ—Ç–æ–≤–æ!
```

**–≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏:** ~70%

#### 2. **Multi-object Tracking** üë•

–û–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤:

```python
# –û–¥–∏–Ω –ø—Ä–æ—Ö–æ–¥ - –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã
prompts = [
    "main character",
    "car in background",
    "flying bird",
    "dog on the street"
]

# SAM 3 –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å—ë –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑
```

#### 3. **Asset Extraction** üì¶

–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è 3D reconstruction:

```python
# –¢–æ—á–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è photogrammetry
prompt = "entire statue without pedestal"

# SAM 3 –ø–æ–Ω–∏–º–∞–µ—Ç "entire" –∏ "without"
```

#### 4. **Complex Scene Segmentation** üèôÔ∏è

–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Å–ª–æ–∂–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:

```python
"all windows on the left building"
"cars moving from left to right"
"people in the foreground but not in the crowd"
```

#### 5. **Cleanup / Paint-out** üé®

–ë—ã—Å—Ç—Ä–∞—è –º–∞—Å–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è:

```python
"all wires and cables"
"modern elements in historical scene"
"tracking markers"
```

---

## üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ NukeSamurai

### –¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å:

**NukeSamurai v1.0:**
- ‚úÖ SAM 2.1 + SAMURAI
- ‚úÖ Bbox prompting
- ‚úÖ GPU acceleration (RTX 4090)
- ‚úÖ ~15-20 —Å–µ–∫ –¥–ª—è 181 –∫–∞–¥—Ä–∞

### –ü–ª–∞–Ω–∏—Ä—É–µ–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è SAM 3:

#### –§–∞–∑–∞ 1: –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (1-2 –Ω–µ–¥–µ–ª–∏)

**–î–æ–±–∞–≤–∏—Ç—å –≤ UI:**
```python
# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
s.addKnob(nuke.Enumeration_Knob(
    'ModelVersion',
    'Model',
    ['SAM 2.1', 'SAM 3.0']
))

# –í—ã–±–æ—Ä —Ç–∏–ø–∞ –ø—Ä–æ–º–ø—Ç–∞
s.addKnob(nuke.Enumeration_Knob(
    'PromptType',
    'Prompt Type',
    ['Bounding Box', 'Text Prompt', 'Visual Exemplar']
))

# –ü–æ–ª–µ –¥–ª—è text prompt
s.addKnob(nuke.String_Knob('TextPrompt', 'Text'))
```

**–û–±–Ω–æ–≤–∏—Ç—å sam2_worker.py:**
```python
if model_version == "SAM3":
    from sam3.model_builder import build_sam3_video_predictor
    
    predictor = build_sam3_video_predictor()
    
    if prompt_type == "text":
        response = predictor.handle_request(
            request=dict(
                type="add_prompt",
                text=text_prompt,
                frame_index=start_frame
            )
        )
```

#### –§–∞–∑–∞ 2: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ (2-4 –Ω–µ–¥–µ–ª–∏)

**Multi-object support:**
```python
# –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ text prompts
s.addKnob(nuke.Multiline_Eval_String_Knob(
    'TextPrompts',
    'Text Prompts (one per line)'
))

# –ö–∞–∂–¥—ã–π –ø—Ä–æ–º–ø—Ç = –æ—Ç–¥–µ–ª—å–Ω–∞—è –º–∞—Å–∫–∞
prompts = text_prompts.split('\n')
for i, prompt in enumerate(prompts):
    mask_output = f"{output_path}_obj{i}_%04d.png"
```

**Visual exemplar prompts:**
```python
# Crop tool –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–∏–º–µ—Ä–∞
s.addKnob(nuke.XY_Knob('ExemplarCrop', 'Exemplar Area'))

# SAM 3 –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã
```

**Interactive refinement:**
```python
# –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä
s.addKnob(nuke.PyScript_Knob('Preview', 'Preview Result'))

# –£—Ç–æ—á–Ω–µ–Ω–∏–µ —Ç–æ—á–∫–∞–º–∏
s.addKnob(nuke.MultiView_Knob('RefinePoints', 'Refine'))
```

#### –§–∞–∑–∞ 3: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (1-2 –Ω–µ–¥–µ–ª–∏)

- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- Batched inference –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è VRAM usage
- Progress bar —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π

### –û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:

| –ú–µ—Ç—Ä–∏–∫–∞ | SAM 2.1 | SAM 3 (–æ–∂–∏–¥–∞–µ—Ç—Å—è) |
|---------|---------|-------------------|
| **Workflow –≤—Ä–µ–º—è** | 100% | ~30% (text prompts!) |
| **–†—É—á–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è** | –ß–∞—Å—Ç–æ | –†–µ–¥–∫–æ |
| **Multi-object** | –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ | –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ |
| **–ö–∞—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫** | –û—Ç–ª–∏—á–Ω–æ | –õ—É—á—à–µ |
| **Inference –≤—Ä–µ–º—è** | 15-20 —Å–µ–∫ | ? (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å) |

---

## üíª –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ:

- **Python:** 3.10+
- **PyTorch:** 2.7.0+
- **CUDA:** 12.6
- **GPU:** NVIDIA —Å CUDA support
- **VRAM:** 8 GB (–º–∏–Ω–∏–º—É–º)
- **RAM:** 16 GB

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ:

- **Python:** 3.12
- **PyTorch:** 2.7.0
- **CUDA:** 12.6
- **GPU:** RTX 4090 –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è
- **VRAM:** 24 GB
- **RAM:** 32 GB
- **SSD:** –î–ª—è –∫—ç—à–∞

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞:

```bash
# 1. –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
conda create -n sam3 python=3.12
conda activate sam3

# 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch
pip install torch==2.7.0 torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu126

# 3. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/facebookresearch/sam3.git
cd sam3

# 4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ SAM 3
pip install -e .

# 5. HuggingFace authentication
pip install huggingface_hub
huggingface-cli login  # –í–≤–µ—Å—Ç–∏ access token
```

### –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:

–ú–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ [HuggingFace](https://huggingface.co/facebook/sam3).

**–¢—Ä–µ–±—É–µ—Ç—Å—è:**
1. –ó–∞–ø—Ä–æ—Å–∏—Ç—å –¥–æ—Å—Ç—É–ø –Ω–∞ HF repo
2. –°–æ–∑–¥–∞—Ç—å access token
3. –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å—Å—è: `huggingface-cli login`

---

## üîÆ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

### SAM 3 - —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ, —ç—Ç–æ –Ω–æ–≤–∞—è –ø–∞—Ä–∞–¥–∏–≥–º–∞!

**–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**

1. **Text prompts** üî•
   - –†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ —É–ø—Ä–æ—â–µ–Ω–∏–µ workflow
   - –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
   - –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤

2. **Visual exemplars** üñºÔ∏è
   - "–ù–∞–π–¥–∏ –ø–æ—Ö–æ–∂–µ–µ"
   - –†–∞–±–æ—Ç–∞ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏ –∏ —Ç–µ–∫—Å—Ç—É—Ä–∞–º–∏
   - –û–¥–Ω–æ—Ä–æ–¥–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –∑–∞ –æ–¥–∏–Ω –∫–ª–∏–∫

3. **Improved architecture** üèóÔ∏è
   - 848M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
   - –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
   - Unified –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ

4. **Advanced features** ‚ö°
   - Multi-object tracking
   - Negative prompts
   - Session management
   - Batched inference

### –î–ª—è VFX –∏–Ω–¥—É—Å—Ç—Ä–∏–∏:

**SAM 3 –º–µ–Ω—è–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã:**

- ‚ùå –ë–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω–æ —Ä–∏—Å–æ–≤–∞—Ç—å bbox
- ‚ùå –ë–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –≤ –∫–∞–¥—Ä–µ
- ‚úÖ –ü—Ä–æ—Å—Ç–æ –æ–ø–∏—Å—ã–≤–∞–µ—Ç–µ —á—Ç–æ –Ω—É–∂–Ω–æ
- ‚úÖ –ú–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–µ—Ç –∏ –Ω–∞—Ö–æ–¥–∏—Ç
- ‚úÖ –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏ –¥–æ 70%

### –ü–ª–∞–Ω—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ NukeSamurai:

**–ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ (1 –º–µ—Å—è—Ü):**
- ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SAM 3
- ‚úÖ –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
- ‚úÖ Text prompts –≤ UI
- ‚úÖ Release v2.0

**–°—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω—ã–µ (2-3 –º–µ—Å—è—Ü–∞):**
- ‚úÖ Multi-object support
- ‚úÖ Visual exemplar prompts
- ‚úÖ Interactive refinement
- ‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ (6+ –º–µ—Å—è—Ü–µ–≤):**
- ‚úÖ Custom fine-tuning –¥–ª—è VFX
- ‚úÖ Integration —Å –¥—Ä—É–≥–∏–º–∏ Nuke tools
- ‚úÖ Real-time preview
- ‚úÖ Cloud processing support

---

## üìö –†–µ—Å—É—Ä—Å—ã

### –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–µ:

- **GitHub:** https://github.com/facebookresearch/sam3
- **–°–∞–π—Ç:** https://ai.meta.com/sam3/
- **HuggingFace:** https://huggingface.co/facebook/sam3
- **Paper:** (–æ–∂–∏–¥–∞–µ—Ç—Å—è)

### –î–∞—Ç–∞—Å–µ—Ç—ã:

- **SA-Co/Gold:** https://huggingface.co/datasets/facebook/saco-gold
- **SA-Co/Silver:** https://huggingface.co/datasets/facebook/saco-silver
- **SA-Co/VEval:** https://huggingface.co/datasets/facebook/saco-veval

### –ü—Ä–∏–º–µ—Ä—ã:

- `examples/sam3_image_predictor_example.ipynb`
- `examples/sam3_video_predictor_example.ipynb`
- `examples/sam3_agent.ipynb`
- `examples/sam3_image_batched_inference.ipynb`

---

## üôè –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

**Meta AI** –∑–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –∏ –æ—Ç–∫—Ä—ã—Ç—ã–π –≤—ã–ø—É—Å–∫ SAM 3.

**NukeSamurai community** –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É –∏ feedback.

---

## üìù –õ–∏—Ü–µ–Ω–∑–∏—è

SAM 3 —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ–¥ **Apache 2.0 License**.

---

**–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏:** 20 –Ω–æ—è–±—Ä—è 2025  
**–ê–≤—Ç–æ—Ä:** NukeSamurai Development Team  
**–í–µ—Ä—Å–∏—è:** 1.0

